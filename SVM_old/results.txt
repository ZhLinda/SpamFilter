1：
10000条数据（9000:1000），linear核，PCA降维  PCA降维的效果挺差的

训练集测试结果：
	The best parameters are {'C': 10.0} with a score of 0.98
			precision    recall  f1-score   support

				0       1.00      1.00      1.00      8128
			    1       1.00      1.00      1.00       872

	  avg / total       1.00      1.00      1.00      9000

训练集交叉验证结果：
	[ 0.88510941  0.89187081  0.88793396  0.88221858  0.8960664 ]
	Accuracy: 0.89 (+/- 0.01)
	
	
2:
5000条数据（4500:500），linear核，自主挑选3006条特征

训练集测试结果；
	The best parameters are {'C': 1000.0} with a score of 0.99

测试集测试结果：
             precision    recall  f1-score   support

        0.0       1.00      1.00      1.00       451
        1.0       1.00      0.96      0.98        49

avg / total       1.00      1.00      1.00       500

混淆矩阵（TP, FP, TN, FN)
[[451   0]
 [  2  47]]

 
3:
5000条数据（4500:5000），linear核，自主挑选3006条特征

训练集+测试集测试结果：
				precision    recall  f1-score   support

          0       1.00      1.00      1.00      4522
          1       1.00      1.00      1.00       478

avg / total       1.00      1.00      1.00      5000

[[4522    0]
 [   2  476]] 
 
 
4:
5000条数据（4500:5000），linear核，自主挑选3006条特征

训练集+测试集测试结果：
				precision    recall  f1-score   support

          0       1.00      1.00      1.00      4522
          1       1.00      0.99      0.99       478

avg / total       1.00      1.00      1.00      5000

[[4520    2]
 [   6  472]]
 
 
5：
5000条数据（4500:5000），高斯核，自主挑选3006条特征

训练集+测试集测试结果：
				precision    recall  f1-score   support

          0       1.00      1.00      1.00      4522
          1       1.00      1.00      1.00       478

avg / total       1.00      1.00      1.00      5000

[[4522    0]
 [   2  476]]

 
6：
5000条数据（4500:5000），高斯核，自主挑选3006条特征

训练集+测试集测试结果：
				precision    recall  f1-score   support

          0       1.00      1.00      1.00      4522
          1       1.00      0.99      0.99       478

avg / total       1.00      1.00      1.00      5000

[[4520    2]
 [   6  472]]
 
7：
10w条数据（80000:100000），线性核，自主挑选3006条特征

训练集+测试集测试结果：
				precision    recall  f1-score   support

          0       0.97      1.00      0.98     89875
          1       0.98      0.73      0.84     10125

avg / total       0.97      0.97      0.97    100000

[[89752   123]
 [ 2697  7428]]
 
8：
训练集4500：测试集10w，线性核/高斯核（二者结果一样），3006条特征

测试集测试结果：
				precision    recall  f1-score   support

          0       0.97      1.00      0.98     89874
          1       0.98      0.73      0.84     10125

avg / total       0.97      0.97      0.97     99999

[[89751   123]
 [ 2697  7428]]

9：
5000条数据（4500:500），线性核，3005条特征，去除了ext_feature_5（文本的平均编码）

测试集测试结果：
				precision    recall  f1-score   support

          0       0.99      1.00      0.99       463
          1       0.94      0.89      0.92        37

avg / total       0.99      0.99      0.99       500

[[461   2]
 [  4  33]]
 
10：
2万条数据（18000:2000），线性核，3005条特征，去除了ext_feature_5（文本的平均编码）

测试集测试结果：
				precision    recall  f1-score   support

          0       0.99      0.99      0.99      1788
          1       0.95      0.91      0.93       212

avg / total       0.98      0.98      0.98      2000

[[1777   11]
 [  20  192]]

11:
5000条数据（4500:500），线性核，3006条特征，class_weight={1:10}

测试集测试结果：
				precision    recall  f1-score   support

          0       0.99      1.00      0.99       453
          1       1.00      0.87      0.93        47

avg / total       0.99      0.99      0.99       500

[[453   0]
 [  6  41]]
 
12:
20000条数据（18000:2000），线性核，5006条特征  看来5000条特征降低了分类效果啊

测试集测试结果：
             precision    recall  f1-score   support

          0       0.98      0.99      0.98      1811
          1       0.86      0.84      0.85       189

avg / total       0.97      0.97      0.97      2000

[[1786   25]
 [  31  158]]
 
13：
5000条数据（4500：500），线性核，3006条特征

测试集测试结果：
				precision    recall  f1-score   support

          0       0.99      1.00      1.00       459
          1       0.97      0.93      0.95        41

avg / total       0.99      0.99      0.99       500

[[458   1]
 [  3  38]]